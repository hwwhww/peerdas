{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PeerDAS Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODOs\n",
    "\n",
    "- [ ] Add attacker nodes\n",
    "- [ ] Increase simulation runs\n",
    "- [ ] Improve sample selection\n",
    "- [ ] Simulate more real peer distribution\n",
    "- [ ] Simulate gossipsub\n",
    "- [ ] Simulate more real node capacity\n",
    "- [ ] Stats of different parameter range\n",
    "- [ ] Add other simulation targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas\n",
    "# %pip install matplotlib\n",
    "# %pip install \"networkx==3.1\"\n",
    "# %pip install \"scipy==1.11.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "BLOB_SIZE = 4096 * 32  # bytes\n",
    "\n",
    "# Simulation\n",
    "# The graph only makes sense if there are only few nodes\n",
    "DRAW_NETWORK_GRAPH = False\n",
    "SIMULATION_RUNS = 10\n",
    "\n",
    "\n",
    "class Config:\n",
    "    #\n",
    "    # Data\n",
    "    #\n",
    "    MAX_BLOBS_PER_BLOCK = 256  # Full danksharding\n",
    "\n",
    "    @property\n",
    "    def DATA_PER_SLOT(self):\n",
    "        return self.MAX_BLOBS_PER_BLOCK * BLOB_SIZE * 4  # including the extension\n",
    "\n",
    "    NUMBER_OF_ROWS = 32  # Number of rows in the 2D data array\n",
    "    NUMBER_OF_COLUMNS = 32  # Number of columns in the 2D data array\n",
    "\n",
    "    @property\n",
    "    def DATA_PER_ROW(self):\n",
    "        # In bytes\n",
    "        return self.DATA_PER_SLOT / self.NUMBER_OF_ROWS\n",
    "\n",
    "    @property\n",
    "    def DATA_PER_COLUMN(self):\n",
    "        # In bytes\n",
    "        return self.DATA_PER_SLOT / self.NUMBER_OF_COLUMNS\n",
    "\n",
    "    @property\n",
    "    def DATA_PER_SAMPLE(self):\n",
    "        # In bytes\n",
    "        return self.DATA_PER_SLOT / (self.NUMBER_OF_COLUMNS * self.NUMBER_OF_ROWS)\n",
    "\n",
    "    #\n",
    "    # Custody\n",
    "    #\n",
    "    SAMPLES_PER_SLOT = 70  # Number of samples per slot\n",
    "    CUSTODY_REQUIREMENT = 2  # Minimum number of both rows and columns an honest node custodies and serves samples from\n",
    "\n",
    "    @property\n",
    "    def CUSTODY_REQUIREMENT_SUPERNODE(self):\n",
    "        return min(self.NUMBER_OF_ROWS, self.NUMBER_OF_COLUMNS)\n",
    "\n",
    "    #\n",
    "    # Capacity\n",
    "    #\n",
    "    SAMPLING_DUE_SECOND = 4  # seconds, the time for a node to sample\n",
    "    BANDWIDTH_UPLINK_NORMAL = 100 * 1000 * 1000 / 8  # Mbps -> bytes/second\n",
    "    BANDWIDTH_UPLINK_SUPERNODE = BANDWIDTH_UPLINK_NORMAL * 10  # bytes/second, supernode has better bandwidth\n",
    "\n",
    "    @property\n",
    "    def NORMAL_CAPACITY(self):\n",
    "        # The bytes of data a normal node can serve in a sampling period\n",
    "        return self.BANDWIDTH_UPLINK_NORMAL * self.SAMPLING_DUE_SECOND\n",
    "    \n",
    "    @property\n",
    "    def SUPERNODE_CAPACITY(self):\n",
    "        # The bytes of data a supernode can serve in a sampling period\n",
    "        return self.BANDWIDTH_UPLINK_SUPERNODE * self.SAMPLING_DUE_SECOND\n",
    "\n",
    "    #\n",
    "    # Networking\n",
    "    #\n",
    "    NUMBER_OF_NODES = 5000  # Number of nodes in the network\n",
    "    PERCENTAGE_OF_SUPERNODE = 1  # Percentage of supernodes in the network\n",
    "    PERCENTAGE_OF_DISHONEST = 10  # Percentage of dishonest nodes in the network\n",
    "\n",
    "    @property\n",
    "    def PERCENTAGE_OF_NORMAL(self):\n",
    "        # Percentage of normal nodes in the network\n",
    "        return 100 - self.PERCENTAGE_OF_SUPERNODE - self.PERCENTAGE_OF_DISHONEST\n",
    "\n",
    "    TARGET_NUMBER_OF_PEERS = 70  # Target number of peers each node has\n",
    "    TARGET_NUMBER_OF_PEERS_SUPERNODE = TARGET_NUMBER_OF_PEERS * 2  # Target number of peers each supernode has; more peers than normal nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "import random\n",
    "from typing import Sequence, Any, NewType\n",
    "\n",
    "\n",
    "rng = random.Random(5566)\n",
    "\n",
    "\n",
    "class LineType(enum.Enum):\n",
    "    ROW = 0\n",
    "    COLUMN = 1\n",
    "\n",
    "\n",
    "class CustodyInfo:\n",
    "    \"\"\"\n",
    "    The custody information of a line (row or column) of the data array.\n",
    "    \"\"\"\n",
    "    custody_nodes: set[int] = set()  # the nodes that custody this line\n",
    "    dishonest_nodes: set[int] = set()  # the nodes that SHOULD custody this line but don't\n",
    "\n",
    "\n",
    "CustodyLog = NewType('CustodyLog', dict[tuple[LineType, int], CustodyInfo])\n",
    "\n",
    "\n",
    "def create_custody_log(config: Config) -> CustodyLog:\n",
    "    custody_log = CustodyLog({})\n",
    "    for line_type in LineType:\n",
    "        for line_index in range(config.NUMBER_OF_ROWS if line_type == LineType.ROW else config.NUMBER_OF_COLUMNS):\n",
    "            custody_log[line_type, line_index] = CustodyInfo()\n",
    "    return custody_log\n",
    "\n",
    "\n",
    "## Peer connections\n",
    "class Node:\n",
    "    id: int\n",
    "    peers: set[int] = set()\n",
    "    peer_scores: dict[int, float] = {}\n",
    "\n",
    "    should_custody_rows: set[int] = set()\n",
    "    should_custody_cols: set[int] = set()\n",
    "    actual_custody_rows: set[int] = set()\n",
    "    actual_custody_cols: set[int] = set()\n",
    "\n",
    "    is_honest: bool = True\n",
    "    is_supernode: bool = False\n",
    "    target_peers: int = 0\n",
    "    capacity: float = 0\n",
    "    sample_attempt_counter: int = 0\n",
    "\n",
    "    def __init__(self, config: Config, id: int) -> None:\n",
    "        self.id = id\n",
    "        self.target_peers = config.TARGET_NUMBER_OF_PEERS\n",
    "        self.capacity = config.NORMAL_CAPACITY\n",
    "        self.is_honest = rng.randint(1, 100) > config.PERCENTAGE_OF_DISHONEST\n",
    "        if self.is_honest:\n",
    "            if rng.randint(1, 100) <= config.PERCENTAGE_OF_SUPERNODE:\n",
    "                self.is_supernode = True\n",
    "                self.target_peers = config.TARGET_NUMBER_OF_PEERS_SUPERNODE\n",
    "                self.capacity = config.SUPERNODE_CAPACITY\n",
    "\n",
    "    def set_custody(self, config: Config, epoch: int, custody_log: CustodyLog) -> None:\n",
    "        if self.is_supernode:\n",
    "            custody_size = config.CUSTODY_REQUIREMENT_SUPERNODE\n",
    "        elif self.is_honest:\n",
    "            custody_size = config.CUSTODY_REQUIREMENT\n",
    "        else:\n",
    "            # TODO\n",
    "            # Dishoenst nodes custody less than CUSTODY_REQUIREMENT\n",
    "            # custody_size = rng.randint(0, CUSTODY_REQUIREMENT - 1)\n",
    "            custody_size = 0\n",
    "\n",
    "        # The rows and columns that this node SHOULD custody\n",
    "        self.should_custody_rows, self.should_custody_cols = get_custody_rows_cols(\n",
    "            config,self.id, epoch, custody_size=config.CUSTODY_REQUIREMENT)\n",
    "        # The rows and columns that this node ACTUALLY custody\n",
    "        self.actual_custody_rows, self.actual_custody_cols = get_custody_rows_cols(\n",
    "            config, self.id, epoch, custody_size=custody_size)\n",
    "\n",
    "        # Update custody log\n",
    "        # NOTE: use `union` instead of `add`\n",
    "        for row in self.should_custody_rows.difference(self.actual_custody_rows):\n",
    "            custody_log[LineType.ROW, row].dishonest_nodes.union(set([self.id]))\n",
    "        for col in self.should_custody_cols.difference(self.actual_custody_cols):\n",
    "            custody_log[LineType.COLUMN, col].dishonest_nodes.union(set([self.id]))\n",
    "\n",
    "        for row in self.actual_custody_rows:\n",
    "            custody_log[LineType.ROW, row].custody_nodes = custody_log[LineType.ROW, row].custody_nodes.union(set([self.id]))\n",
    "        for col in self.actual_custody_cols:\n",
    "            custody_log[LineType.COLUMN, col].custody_nodes = custody_log[LineType.COLUMN, col].custody_nodes.union(set([self.id]))\n",
    "\n",
    "\n",
    "#\n",
    "# Custody helpers\n",
    "#\n",
    "\n",
    "def cycle(seq: Sequence[Any], start: int) -> Any:\n",
    "    while True:\n",
    "        yield seq[start]\n",
    "        start = (start + 1) % len(seq)\n",
    "\n",
    "\n",
    "def get_custody_lines(config: Config, node_id: int, epoch: int, custody_size: int, line_type: LineType) -> list[int]:\n",
    "    bound = config.NUMBER_OF_ROWS if line_type else config.NUMBER_OF_COLUMNS\n",
    "    all_items = list(range(bound))\n",
    "    line_index = (node_id + epoch) % bound\n",
    "    iterator = cycle(all_items, line_index)\n",
    "    return [next(iterator) for _ in range(custody_size)]\n",
    "\n",
    "\n",
    "def get_custody_rows_cols(config: Config, node_id: int, epoch: int, custody_size: int) -> tuple[set[int], set[int]]:\n",
    "    rows = get_custody_lines(config, node_id, epoch, custody_size, line_type=LineType.ROW)\n",
    "    cols = get_custody_lines(config, node_id, epoch, custody_size, line_type=LineType.COLUMN)\n",
    "\n",
    "    assert len(rows) == len(cols) == custody_size\n",
    "    return set(rows), set(cols)\n",
    "\n",
    "\n",
    "def get_node_ids_by_line_index(config: Config, epoch: int, line_index: int, line_type: LineType) -> list[int]:\n",
    "    # NOTE: not in-use in this simulation, but demonstrates how to get node ids by line_index of a row or column\n",
    "    for node_id in range(config.NUMBER_OF_NODES):\n",
    "        custody_items = get_custody_lines(config, node_id, epoch, custody_size=config.CUSTODY_REQUIREMENT, line_type=line_type)\n",
    "        if line_index in custody_items:\n",
    "            yield node_id\n",
    "\n",
    "\n",
    "def get_custodian_peers(nodes: Sequence[Node], node_id: int, line_type: LineType, line_index: int,\n",
    "                        custody_log: CustodyLog) -> Sequence[int]:\n",
    "    \"\"\"\n",
    "    Get the peers that custody the given ``line_index`` line of a row or column.\n",
    "    \"\"\"\n",
    "    do_you_have_msg = custody_log[line_type, line_index].custody_nodes\n",
    "    dishonest_nodes = custody_log[line_type, line_index].dishonest_nodes\n",
    "    merged_nodes = do_you_have_msg.union(dishonest_nodes)\n",
    "    return nodes[node_id].peers.intersection(merged_nodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation assumptions and logic\n",
    "\n",
    "### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data per slot:\t134217.728 KB\n",
      "Data per row:\t4194.304 KB\n",
      "Data per column:\t4194.304 KB\n",
      "Data per sample:\t131.072 KB\n",
      "Required downlink bandwidth per slot with 4 seconds sampling time:\t18.350080000000002 Mbps\n"
     ]
    }
   ],
   "source": [
    "config_demo = Config()\n",
    "\n",
    "print(f'Data per slot:\\t{config_demo.DATA_PER_SLOT / 1000} KB')\n",
    "print(f'Data per row:\\t{config_demo.DATA_PER_ROW / 1000} KB')\n",
    "print(f'Data per column:\\t{config_demo.DATA_PER_COLUMN / 1000} KB')\n",
    "print(f'Data per sample:\\t{config_demo.DATA_PER_SAMPLE / 1000} KB')\n",
    "required_downlink_bandwidth = (config_demo.DATA_PER_SAMPLE * config_demo.SAMPLES_PER_SLOT) / config_demo.SAMPLING_DUE_SECOND / 1000 / 1000 * 8\n",
    "print(f'Required downlink bandwidth per slot with {config_demo.SAMPLING_DUE_SECOND} seconds sampling time:\\t{required_downlink_bandwidth} Mbps')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P2P network topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all nodes with naive topology and custody\n",
    "def set_peers(nodes: Sequence[Node]) -> None:\n",
    "    \"\"\"\n",
    "    Set peers for each node. Naive implementation.\n",
    "    \"\"\"\n",
    "    for n in nodes:\n",
    "        # TODO: set different distribution\n",
    "        if len(n.peers) < n.target_peers:\n",
    "            selectable_node_ids = set(p.id for p in nodes if len(p.peers) < p.target_peers)\n",
    "            selectable_peers = selectable_node_ids.difference(n.peers.union(set([n.id])))\n",
    "            new_peers = set()\n",
    "            need_peer_count = n.target_peers - len(n.peers)\n",
    "            if need_peer_count > 0:\n",
    "                new_peers = rng.sample(list(selectable_peers), k=min(need_peer_count, len(selectable_peers)))\n",
    "            n.peers = n.peers.union(new_peers)\n",
    "            for new_peer_id in new_peers:\n",
    "                nodes[n.id].peer_scores[new_peer_id] = 100\n",
    "            for peer_id in new_peers:\n",
    "                # NOTE: DO NOT USE nodes[peer_id].peers.add(n.id)  <-- side effect!\n",
    "                nodes[peer_id].peers = nodes[peer_id].peers.union(set([n.id]))\n",
    "                nodes[peer_id].peer_scores[n.id] = 100\n",
    "\n",
    "\n",
    "def get_nodes(config: Config, epoch: int, node_count: int, custody_log: CustodyLog) -> Sequence[Node]:\n",
    "    \"\"\"\n",
    "    Initialize nodes with peers and their custodies.\n",
    "    \"\"\"\n",
    "    all_nodes = [Node(id=id, config=config) for id in range(node_count)]\n",
    "    set_peers(all_nodes)\n",
    "    for node in all_nodes:\n",
    "        node.set_custody(config, epoch, custody_log)\n",
    "\n",
    "    return all_nodes\n",
    "\n",
    "# Temparary log for simulation stats\n",
    "custody_log_demo = create_custody_log(config_demo)\n",
    "all_nodes_demo = get_nodes(config=config_demo, epoch=0, node_count=config_demo.NUMBER_OF_NODES, custody_log=custody_log_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "\n",
    "if DRAW_NETWORK_GRAPH:\n",
    "    g = nx.Graph()\n",
    "    for node in all_nodes_demo:\n",
    "        g.add_node(node.id)\n",
    "    for node in all_nodes_demo:\n",
    "        for peer_id in node.peers:\n",
    "            g.add_edge(node.id, peer_id)\n",
    "\n",
    "    nx.draw(g, node_size=2, alpha=0.5, width=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average peer count: 70.64\n",
      "Average custody lines (rows + columns): 4.1424\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node.id</th>\n",
       "      <th>len(peers)</th>\n",
       "      <th>len(should_custody_rows)</th>\n",
       "      <th>len(should_custody_cols)</th>\n",
       "      <th>len(actual_custody_rows)</th>\n",
       "      <th>len(actual_custody_cols)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4995</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4996</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4997</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>4998</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>4999</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      node.id  len(peers)  len(should_custody_rows)  len(should_custody_cols)  \\\n",
       "0           0          70                         2                         2   \n",
       "1           1          70                         2                         2   \n",
       "2           2          70                         2                         2   \n",
       "3           3          70                         2                         2   \n",
       "4           4          70                         2                         2   \n",
       "...       ...         ...                       ...                       ...   \n",
       "4995     4995          70                         2                         2   \n",
       "4996     4996          66                         2                         2   \n",
       "4997     4997          70                         2                         2   \n",
       "4998     4998          70                         2                         2   \n",
       "4999     4999          70                         2                         2   \n",
       "\n",
       "      len(actual_custody_rows)  len(actual_custody_cols)  \n",
       "0                            2                         2  \n",
       "1                            0                         0  \n",
       "2                            2                         2  \n",
       "3                            0                         0  \n",
       "4                            2                         2  \n",
       "...                        ...                       ...  \n",
       "4995                         2                         2  \n",
       "4996                         2                         2  \n",
       "4997                         2                         2  \n",
       "4998                         0                         0  \n",
       "4999                         2                         2  \n",
       "\n",
       "[5000 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "stats = []\n",
    "for node in all_nodes_demo:\n",
    "    stats.append({\n",
    "        \"node.id\": node.id,\n",
    "        \"len(peers)\": len(node.peers),\n",
    "        \"len(should_custody_rows)\": len(node.should_custody_rows),\n",
    "        \"len(should_custody_cols)\": len(node.should_custody_cols),\n",
    "        \"len(actual_custody_rows)\": len(node.actual_custody_rows),\n",
    "        \"len(actual_custody_cols)\": len(node.actual_custody_cols),\n",
    "    })\n",
    "\n",
    "avg_peer_count = sum(x[\"len(peers)\"] for x in stats) / len(stats)\n",
    "print(f\"Average peer count: {avg_peer_count}\")\n",
    "if any(x[\"len(peers)\"] == 0 for x in stats):\n",
    "    print(\"WARNING: Some nodes have no peers!\")\n",
    "\n",
    "avg_custody_count = sum((x[\"len(actual_custody_rows)\"] + x[\"len(actual_custody_cols)\"]) for x in stats) / len(stats)\n",
    "print(f\"Average custody lines (rows + columns): {avg_custody_count}\")\n",
    "for index, info in custody_log_demo.items():\n",
    "    line_type, line_index = index\n",
    "    if len(info.custody_nodes) == 0:\n",
    "        print(f\"WARNING: No node custody {line_type} {line_type}!\")\n",
    "\n",
    "stats = pd.DataFrame(stats)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Supernode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of supernodes: 46 (0.9199999999999999%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node.id</th>\n",
       "      <th>len(peers)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>188</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>196</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4448</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4457</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4586</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4728</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4793</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    node.id  len(peers)\n",
       "0       102         140\n",
       "1       121         140\n",
       "2       188         140\n",
       "3       194         140\n",
       "4       196         140\n",
       "..      ...         ...\n",
       "41     4448         140\n",
       "42     4457         140\n",
       "43     4586         140\n",
       "44     4728         140\n",
       "45     4793         139\n",
       "\n",
       "[46 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "stats = []\n",
    "\n",
    "for node in all_nodes_demo:\n",
    "    if node.is_supernode:\n",
    "        stats.append({\n",
    "            \"node.id\": node.id,\n",
    "            \"len(peers)\": len(node.peers),\n",
    "        })\n",
    "print(f'Number of supernodes: {len(stats)} ({len(stats) / len(all_nodes_demo) * 100}%)')\n",
    "stats = pd.DataFrame(stats)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gossip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gossip(config: Config, nodes: Sequence[Node], custody_row_log: dict[set[int]], custody_col_log: dict[set[int]]) -> None:\n",
    "    \"\"\"\n",
    "    Gossip the custody information to peers.\n",
    "    \"\"\"\n",
    "    # TODO: Consider capacity\n",
    "    uncovered_rows = [line for line in custody_row_log if not any(line)]\n",
    "    uncovered_cols = [line for line in custody_col_log if not any(line)]\n",
    "    return uncovered_rows, uncovered_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling\n",
    "\n",
    "Each node does:\n",
    "1. pseudo-randomly choose the sample point.\n",
    "2. Compute the peer list of peers who should have downloaded the given lines.\n",
    "3. Request the peer can provide the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling\n",
    "\n",
    "def sample_peer(config: Config, nodes: Sequence[Node], peer_id: int, line_type: LineType, line_index: int) -> bool:\n",
    "    # TODO: now it ignore if the peer may have the sample by another line_type\n",
    "    # If the peer has no enough capacity, it can not serve the sample\n",
    "    nodes[peer_id].capacity -= config.DATA_PER_SAMPLE\n",
    "    if nodes[peer_id].capacity < 0:\n",
    "        return False\n",
    "\n",
    "    return (line_index in nodes[peer_id].actual_custody_rows) if line_type else (line_index in nodes[peer_id].actual_custody_cols)\n",
    "\n",
    "\n",
    "def sample_by_line(config: Config, nodes: Sequence[Node], node_id: int,\n",
    "                   line_type: LineType, line_index: int, custody_log: CustodyInfo) -> bool:\n",
    "    \"\"\"\n",
    "    Sample a peer that custodies the given ``line_index``.\n",
    "    \"\"\"\n",
    "    custodian_peers = get_custodian_peers(nodes, node_id,\n",
    "                                          line_type=line_type, line_index=line_index,\n",
    "                                          custody_log=custody_log)\n",
    "\n",
    "    if len(custodian_peers) == 0:\n",
    "        return False\n",
    "\n",
    "    # shuffle the order\n",
    "    custodian_peers = list(custodian_peers)\n",
    "    rng.shuffle(custodian_peers)\n",
    "    for peer_id in custodian_peers:\n",
    "        nodes[node_id].sample_attempt_counter += 1\n",
    "        if sample_peer(config, nodes, peer_id, line_type=line_type, line_index=line_index):\n",
    "            return True\n",
    "        else:\n",
    "            nodes[node_id].peer_scores[peer_id] -= 1\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def try_sample_by_line(config: Config, nodes: Sequence[Node], node_id: int,  line_type: LineType, line_index: int,\n",
    "                       custody_log: CustodyLog, covered: list[int], index: int) -> None:\n",
    "    line_success = sample_by_line(config, nodes, node_id,\n",
    "                                  line_type=line_type, line_index=line_index, custody_log=custody_log)\n",
    "    if line_success:\n",
    "        covered[index] = 1\n",
    "    return line_success\n",
    "\n",
    "\n",
    "def sample(config: Config, nodes: Sequence[Node], custody_log: CustodyLog):\n",
    "    sample_results = []  # 1 if all samples are successful, 0 if one of it has failed\n",
    "    reconstructions = []  # 1 if node is able to recover the data with the sampled rows/cols, 0 if unable\n",
    "    sample_attempt_counts = []  # number of tries to sample all samples\n",
    "\n",
    "    # TODO: parallelize it\n",
    "    for node_id in range(len(nodes)):\n",
    "        rows_uncovered , cols_uncovered, samples_uncovered = ([] for _ in range(3))\n",
    "        rows_covered = [0 for _ in range(config.NUMBER_OF_ROWS)]\n",
    "        cols_covered = [0 for _ in range(config.NUMBER_OF_COLUMNS)]\n",
    "        success = True\n",
    "\n",
    "        # Select `SAMPLES_PER_SLOT` points\n",
    "        sample_points = rng.sample(list(range(config.NUMBER_OF_ROWS * config.NUMBER_OF_COLUMNS)), config.SAMPLES_PER_SLOT)\n",
    "        for point in sample_points:\n",
    "            row = point // config.NUMBER_OF_COLUMNS\n",
    "            col = point % config.NUMBER_OF_COLUMNS\n",
    "\n",
    "            first_try = rng.choice([0, 1])\n",
    "            first_try_line_type = LineType.ROW if first_try else LineType.COLUMN\n",
    "            second_try_line_type = LineType.COLUMN if first_try else LineType.ROW\n",
    "            first_try_line_index = row if first_try else col\n",
    "            second_try_line_index = col if first_try else row\n",
    "            first_try_covered_log = rows_covered if first_try else cols_covered\n",
    "            second_try_covered_log = cols_covered if first_try else rows_covered\n",
    "            index = row if first_try else col\n",
    "\n",
    "            # First try the row or column\n",
    "            line_success = try_sample_by_line(config, nodes, node_id,\n",
    "                                              line_type=first_try_line_type,\n",
    "                                              line_index=first_try_line_index,\n",
    "                                              custody_log=custody_log,\n",
    "                                              covered=first_try_covered_log, index=index)\n",
    "            # Second try: try another LineType\n",
    "            if not line_success:\n",
    "                line_success = try_sample_by_line(config, nodes, node_id,\n",
    "                                                  line_type=second_try_line_type,\n",
    "                                                  line_index=second_try_line_index,\n",
    "                                                  custody_log=custody_log,\n",
    "                                                  covered=second_try_covered_log, index=index)\n",
    "                if not line_success:\n",
    "                    success = False\n",
    "\n",
    "        sample_results.append(1) if success else sample_results.append(0)\n",
    "        sample_attempt_counts.append(nodes[node_id].sample_attempt_counter)\n",
    "\n",
    "        # Reconstruct\n",
    "        rows_uncovered.append(sum(1 if x == 0 else 0 for x in rows_covered))\n",
    "        cols_uncovered.append(sum(1 if x == 0 else 0 for x in cols_covered))\n",
    "        samples_uncovered.append(rows_uncovered[-1] * cols_uncovered[-1])\n",
    "\n",
    "        # If more than 1/4 of the row/col is unavailable, the node can not reconstruct the data\n",
    "        if samples_uncovered[-1] > config.NUMBER_OF_ROWS * config.NUMBER_OF_COLUMNS / 4:\n",
    "            reconstructions.append(0)\n",
    "        else:\n",
    "            reconstructions.append(1)\n",
    "\n",
    "    return sample_results, reconstructions, sample_attempt_counts\n",
    "\n",
    "\n",
    "sample_results, reconstructions, sample_attempt_counts = sample(\n",
    "    config_demo, all_nodes_demo, custody_log=custody_log_demo,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_failed_sample</th>\n",
       "      <th>has_failed_sample</th>\n",
       "      <th>reconstructable</th>\n",
       "      <th>not_reconstructable</th>\n",
       "      <th>nodes_no_enough_bandwidth</th>\n",
       "      <th>avg_sample_attempt_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.985</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>69.9816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no_failed_sample  has_failed_sample  reconstructable  not_reconstructable  \\\n",
       "0             0.985              0.015              1.0                  0.0   \n",
       "\n",
       "   nodes_no_enough_bandwidth  avg_sample_attempt_counts  \n",
       "0                          0                    69.9816  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "stats = [{\n",
    "    \"no_failed_sample\": sum(sample_results) / len(sample_results),\n",
    "    \"has_failed_sample\": 1 - sum(sample_results) / len(sample_results),\n",
    "    \"reconstructable\": sum(reconstructions) / len(reconstructions),\n",
    "    \"not_reconstructable\": 1 - sum(reconstructions) / len(reconstructions),\n",
    "    \"nodes_no_enough_bandwidth\": len([n for n in all_nodes_demo if n.capacity < 0]),\n",
    "    \"avg_sample_attempt_counts\": sum(sample_attempt_counts) / len(sample_attempt_counts),\n",
    "}]\n",
    "\n",
    "stats = pd.DataFrame(stats)\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation results\n",
    "\n",
    "### 1. Node count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_x_values = [5000, 7500, 10000]  # Number of nodes in the network\n",
    "\n",
    "g_sample_results, g_reconstructions, g_sample_attempt_counts = ({} for _ in range(3))\n",
    "\n",
    "def to_dict_stats(all_sample_results, all_reconstructions, all_sample_attempt_counts, config_field, x_values):\n",
    "    for x in x_values:\n",
    "        config = Config()\n",
    "        setattr(config, config_field, x)\n",
    "\n",
    "        all_sample_results[x] = []\n",
    "        all_reconstructions[x] = []\n",
    "        all_sample_attempt_counts[x] = []\n",
    "        for _ in range(SIMULATION_RUNS):\n",
    "            custody_log = create_custody_log(config)\n",
    "\n",
    "            nodes = get_nodes(config, epoch=0, node_count=x, custody_log=custody_log)\n",
    "            sample_results, reconstructions, sample_attempt_counts = sample(config, nodes, custody_log=custody_log)\n",
    "\n",
    "            all_sample_results[x].append(sample_results)\n",
    "            all_reconstructions[x].append(reconstructions)\n",
    "            all_sample_attempt_counts[x].append(sample_attempt_counts)\n",
    "\n",
    "to_dict_stats(g_sample_results, g_reconstructions, g_sample_attempt_counts, config_field=\"NUMBER_OF_NODES\", x_values=g_x_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_stats(all_sample_results, all_reconstructions, all_sample_attempt_counts, x_axis_name):\n",
    "    stats_results = []\n",
    "    for x, sample_results_of_x in all_sample_results.items():\n",
    "        flatten_success = [a for b in sample_results_of_x for a in b]\n",
    "        flatten_reconstructions = [a for b in all_reconstructions[x] for a in b]\n",
    "        flatten_sample_attempt_counts = [a for b in all_sample_attempt_counts[x] for a in b]\n",
    "        avg_success_ratio = sum(flatten_success) / len(flatten_success)\n",
    "        avg_reconstructable_ratio = sum(flatten_reconstructions) / len(flatten_reconstructions)\n",
    "        avg_sample_attempt_counts = sum(flatten_sample_attempt_counts) / len(flatten_sample_attempt_counts)\n",
    "        stats_results.append({\n",
    "            f\"{x_axis_name}\": x,\n",
    "            \"len(flatten)\": len(flatten_success),\n",
    "            \"avg_all_successful_sample_ratio\": avg_success_ratio,\n",
    "            \"avg_reconstructable_ratio\": avg_reconstructable_ratio,\n",
    "            \"avg_sample_attempt_counts\": avg_sample_attempt_counts,\n",
    "        })\n",
    "    return stats_results\n",
    "\n",
    "stats_results = get_stats(g_sample_results, g_reconstructions, g_sample_attempt_counts, x_axis_name=\"node_count\")\n",
    "node_counts_results = pd.DataFrame(stats_results)\n",
    "node_counts_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import numpy as np\n",
    "\n",
    "# draw chart of stats_sample_results\n",
    "fig, ax = plt.subplots()\n",
    "x = np.arange(len(g_x_values))\n",
    "width = 0.2\n",
    "\n",
    "ax.set_ylabel('Percentage')\n",
    "ax.set_title('Sampling results of one slot')\n",
    "rects1 = ax.bar(x - width / 2, node_counts_results['avg_all_successful_sample_ratio'], width, label='The rate of nodes that has no failed sample')\n",
    "rects2 = ax.bar(x + width / 2, node_counts_results['avg_reconstructable_ratio'], width, label='The rate of nodes that can recover the data')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "ax.set_xticklabels(g_x_values)\n",
    "ax.legend(bbox_to_anchor=(0, -0.3, 0, 0.5), loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. `SAMPLES_PER_SLOT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_x_values = [25, 50, 75, 100]  # Number of nodes in the network\n",
    "\n",
    "g_sample_results, g_reconstructions, g_sample_attempt_counts = ({} for _ in range(3))\n",
    "\n",
    "to_dict_stats(g_sample_results, g_reconstructions, g_sample_attempt_counts, config_field=\"SAMPLES_PER_SLOT\", x_values=g_x_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_results = get_stats(g_sample_results, g_reconstructions, g_sample_attempt_counts, x_axis_name=\"SAMPLES_PER_SLOT\")\n",
    "samples_per_slot_results = pd.DataFrame(stats_results)\n",
    "samples_per_slot_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Capacity\n",
    "\n",
    "Check the capcity of various `MAX_BLOBS_PER_BLOCK`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_sample_results, g_reconstructions, g_sample_attempt_counts, g_neg_capacities = ({} for _ in range(4))\n",
    "\n",
    "param_blobs_per_block = [128, 256, 512]\n",
    "\n",
    "def to_capacity_dict_stats(all_sample_results, all_reconstructions, all_sample_attempt_counts, all_neg_capacities):\n",
    "    for blobs_per_block in param_blobs_per_block:\n",
    "        config = Config()\n",
    "        config.MAX_BLOBS_PER_BLOCK = blobs_per_block\n",
    "\n",
    "        all_sample_results[blobs_per_block] = []\n",
    "        all_reconstructions[blobs_per_block] = []\n",
    "        all_neg_capacities[blobs_per_block] = []\n",
    "        all_sample_attempt_counts[blobs_per_block] = []\n",
    "        for _ in range(SIMULATION_RUNS):\n",
    "            custody_log = create_custody_log(config)\n",
    "\n",
    "            nodes = get_nodes(config, epoch=0, node_count=config.NUMBER_OF_NODES, custody_log=custody_log)\n",
    "            sample_results, reconstructions, sample_attempt_counts = sample(config, nodes, custody_log=custody_log)\n",
    "\n",
    "            all_sample_results[blobs_per_block].append(sample_results)\n",
    "            all_reconstructions[blobs_per_block].append(reconstructions)\n",
    "            all_sample_attempt_counts[blobs_per_block].append(sample_attempt_counts)\n",
    "            all_neg_capacities[blobs_per_block].append([int(n.capacity < 0) for n in nodes])\n",
    "\n",
    "to_capacity_dict_stats(g_sample_results, g_reconstructions, g_sample_attempt_counts, g_neg_capacities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_results = get_stats(g_sample_results, g_reconstructions, g_sample_attempt_counts, x_axis_name=\"blobs_per_block\")\n",
    "\n",
    "for index, (blobs_per_block, sample_results) in enumerate(g_sample_results.items()):\n",
    "    capacities = g_neg_capacities[blobs_per_block]\n",
    "    flatten_capacities = [x for y in capacities for x in y]\n",
    "    avg_capacities = sum(1 for c in flatten_capacities if c > 0) / SIMULATION_RUNS\n",
    "    stats_results[index][\"#nodes_no_enough_bandwidth\"] = avg_capacities\n",
    "\n",
    "blobs_per_block_stats_results = pd.DataFrame(stats_results)\n",
    "blobs_per_block_stats_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3102",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
